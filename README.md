# ðŸš€ Fine-Tuning LLaMA-2 7B for Python Code Generation & Bug Fixing (with LoRA)

This project focuses on fine-tuning the open-weight **LLaMA-2 7B** model using **LoRA (Low-Rank Adaptation)** for domain-specific code generation and bug fixing in Python. The goal is to build a lightweight, cost-efficient code assistant that outperforms the base model on custom tasks.

---

## ðŸ§  **Why This Project**
- Enhance LLMs to **generate high-quality Python code** for real-world coding problems.
- Create a model capable of **bug fixing + refactoring suggestions**.
- Demonstrate **efficient fine-tuning (LoRA)** to reduce GPU + memory requirements.

---

## ðŸ“‚ **Project Structure**
